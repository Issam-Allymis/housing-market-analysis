{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Upload dataset file into explorer panel.\n",
        "* Inspect the data and save it under ../house-price-20211124T154130Z-001\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Extract file through terminal, using command 'unzip file_name.zip' \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Archive:  archive.zip\n",
        "  inflating: house-metadata.txt      \n",
        "  inflating: house-price-20211124T154130Z-001/house-price/house_prices_records.csv  \n",
        "  inflating: house-price-20211124T154130Z-001/house-price/inherited_houses.csv  \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory\n",
        "We need to change the working directory from its current folder to its parent folder\n",
        "\n",
        "We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Import packages using the 'import' statement followed by the name of the package. For example, 'import pandas' which is commonly used for data manipulation and analysis. This is  followed by and alias of your choice, preferably as pd although it is arbitrary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "Load the dataset using the pandas method '.read_csv', and sample it to retrieve only 20% of the dataframe, ensuring reproducibility by specifying a random_state. Then, use the 'shape()' method to analyze the number of rows and columns in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/workspace/housing-market-analysis/house-price-20211124T154130Z-001/house-price/house_prices_records.csv\")\n",
        "df = df.sample(frac=0.2, random_state=101)\n",
        "print(df.shape)\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "* DataFrame information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "df.dtypes['WoodDeckSF']\n",
        "df.dtypes['BsmtExposure']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['WoodDeckSF'].fillna(0.0)\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Using feature_engine to replace all numeical & categorical missing data\n",
        "* Using sklearn.preprocessing to scale all the numerical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identify missing values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Separate columns by data type\n",
        "numeric_cols = df.select_dtypes(include=['int', 'float']).columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# Impute missing values for numeric columns using median\n",
        "numeric_imputer = MeanMedianImputer(imputation_method='median')\n",
        "df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "# Impute missing values for categorical columns using most frequent\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Heatmap\n",
        "I used a heatmap to visualize all the numerical variables in the dataset and gain insight into which features correlate the most and which correlate the least."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "corr_matrix = df[numeric_cols].corr()\n",
        "sns.heatmap(corr_matrix, cmap='YlGnBu', annot=True, fmt=\".2f\", annot_kws={\"size\": 8.5})\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* All missing columns have been filled in "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as they support your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/collection') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "df.to_csv(f\"outputs/datasets/collection/house-price-2021.csv\",index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
